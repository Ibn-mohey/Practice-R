---
title: "Prediction Assignment Writeup"
author: "Abd-elrhman mohey"
date: "11/24/2020"
output:
  html_document:
    keep_md: yes
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## load libraries 

```{r}
library(data.table)
library(caret)
library(ggplot2)
library(randomForest)
library(rpart)
library(rpart.plot)
library(rattle)
set.seed(12345)
```

## load data 
```{r}

train = read.csv("pml-training.csv",na.strings= c("", "NA"))
test = read.csv("pml-testing.csv",na.strings= c("", "NA"))
```

## explore the data 

```{r}
head(train)
```

```{r}
summary(train)
```


```{r}
dim(train)
dim(test)
```

## cleaning data set 

there seems to be alot of NA cloumns lets remove any column with 80 or more of it's data mssing.

```{r}
#Remove NA cols
todrop_columns <-colSums(is.na(train))<.8*nrow(train)
train <- train[,todrop_columns]
test <- test[,todrop_columns]
dim(train)
dim(test)
```
now we have 60 column out of 160 column that mean there was 100 extra column at least 

```{r}
summary(train)
```


```{r}
#convert them into factors 
cols <- c("classe")
train[cols] <- lapply(train[cols], factor)
```


```{r}
colnames(train) == colnames(test)
```
i just wanted to check we didnt remove needed column from one of the data sets lets check the last column 
```{r}
head(train[60])
head(test[60])
```
looks like the last column is more like and id 

## explore more 
see the distripution of the classes 
```{r}
barplot(table(train$classe))
```

## split the train data set 


```{r}
intrain <- createDataPartition(y = train$classe ,  p = 0.8, list = FALSE)
training <- train[intrain, ] 
testing <- train[-intrain, ]
```

```{r}
barplot(table(train$classe))
```

## start fitting the models 

### random forest 
lets start with random forest with classe to predect based on all other variables with out the frist 6 vairables which i think are irrlevent 
```{r}
 
model_rf <- randomForest( classe ~ .,  data =training[6:60], method="class")
```

lets evaluate that model 


```{r}
pred_rf <- predict(model_rf, testing, type = "class")
rf1 <- table(pred_rf, testing$classe)
confusionMatrix(rf1)
```
99 % accuracy with this model 

### Liner Discriminant Analysis
same idea with LDA 
```{r}
model_lda <- train(classe ~ ., data = training[6:60], method = "lda")
```

```{r}
pred_lda <- predict(model_lda, testing)
lda1 <- table(pred_lda, testing$classe)
confusionMatrix(lda1)
```
poor accuracy with only 70 %

### Recursive Partitioning and Regression Trees

```{r}
model_rpart <- train(classe ~ ., data = training[6:60], method = "rpart")
pred_rpart<- predict(model_rpart, testing)
rpart1 <- table(pred_rpart, testing$classe)
confusionMatrix(rpart1)
```
that model was poor accuracy with only 49%
plot the tree 

```{r}
library(rattle)
fancyRpartPlot(model_rpart$finalModel)
```
## model selection

## summury
it looks like the random forest model has the higest Accuracy  so i will stick with it 
```{r}
final_data <- predict(model_rf, test, type = "class")
final_data
```

```{r}
barplot(table(final_data))
```

